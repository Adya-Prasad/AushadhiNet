{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "from tqdm import  tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e7f29e",
   "metadata": {},
   "source": [
    "## 1. Preprocessing Hackathon official data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76540a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_ecg_file():\n",
    "    \"\"\"Create a sample ECG file for testing\"\"\"\n",
    "    print(\"Creating sample ECG data file...\")\n",
    "    \n",
    "    # Generate synthetic ECG data\n",
    "    time_points = 5000  # Shorter for demo\n",
    "    t = np.linspace(0, 10, time_points)\n",
    "    \n",
    "    # Simulate ECG signal\n",
    "    ecg_signal = (\n",
    "        0.8 * np.sin(2 * np.pi * 1.2 * t) +  # Main heartbeat\n",
    "        0.3 * np.sin(2 * np.pi * 5 * t) +    # P-wave component\n",
    "        0.1 * np.sin(2 * np.pi * 15 * t) +   # QRS complex\n",
    "        0.05 * np.random.normal(0, 1, time_points)  # Noise\n",
    "    )\n",
    "    \n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame({'ecg_values': ecg_signal})\n",
    "    df.to_csv('sample_ecg_data.csv', index=False)\n",
    "    \n",
    "    print(f\"Sample ECG data saved to 'sample_ecg_data.csv' with {len(ecg_signal)} data points\")\n",
    "    \n",
    "    # Plot the sample\n",
    "    plt.figure(figsize=(30, 5))\n",
    "    plt.plot(t[:1000], ecg_signal[:1000])  # Plot first 1000 points\n",
    "    plt.title('Sample ECG Signal (First 1000 points)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('sample_ecg_plot.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return 'sample_ecg_data.csv'\n",
    "\n",
    "def convert_text_to_csv():\n",
    "    \"\"\"Convert text file with ECG values to CSV\"\"\"\n",
    "    file_path = input(\"Enter path to your text file with ECG values: \").strip()\n",
    "    \n",
    "    try:\n",
    "        # Try different delimiters\n",
    "        for delimiter in [',', ' ', '\\t', ';']:\n",
    "            try:\n",
    "                data = pd.read_csv(file_path, delimiter=delimiter, header=None)\n",
    "                if data.shape[1] > 1 or len(data) > 10:  # Valid data found\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        print(f\"Loaded data with shape: {data.shape}\")\n",
    "        \n",
    "        # If multiple columns, ask which one to use\n",
    "        if data.shape[1] > 1:\n",
    "            print(f\"Found {data.shape[1]} columns. Which column contains ECG data?\")\n",
    "            for i in range(data.shape[1]):\n",
    "                print(f\"Column {i}: {data.iloc[:5, i].values}\")\n",
    "            \n",
    "            col_idx = int(input(\"Enter column index (0-based): \"))\n",
    "            ecg_data = data.iloc[:, col_idx]\n",
    "        else:\n",
    "            ecg_data = data.iloc[:, 0]\n",
    "        \n",
    "        # Save as CSV\n",
    "        output_file = file_path.replace('.txt', '_converted.csv').replace('.dat', '_converted.csv')\n",
    "        ecg_df = pd.DataFrame({'ecg_values': ecg_data})\n",
    "        ecg_df.to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f\"Converted data saved to: {output_file}\")\n",
    "        print(f\"Data points: {len(ecg_data)}\")\n",
    "        \n",
    "        return output_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error converting file: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*50)\n",
    "    print(\"ECG DATA PREPARATION HELPER\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\nChoose an option:\")\n",
    "    print(\"1. Create sample ECG data for testing\")\n",
    "    print(\"2. Convert your text/dat file to CSV\")\n",
    "    print(\"3. Exit\")\n",
    "    \n",
    "    choice = input(\"\\nEnter choice (1-3): \").strip()\n",
    "    \n",
    "    if choice == '1':\n",
    "        create_sample_ecg_file()\n",
    "    elif choice == '2':\n",
    "        convert_text_to_csv()\n",
    "    elif choice == '3':\n",
    "        print(\"Goodbye!\")\n",
    "    else:\n",
    "        print(\"Invalid choice\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518371fb",
   "metadata": {},
   "source": [
    "### 2. Converting `dataset/drugdata/DICT_rank.xlsx` to `dataset/drugdata/DICT_rank.csv` for compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd226ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dictrank_to_csv():\n",
    "    \"\"\"\n",
    "    Convert DICTrank Excel dataset to CSV with specific rules:\n",
    "    1. Fill NA in Column G (Keywords) and Column H (DIC Severity Level)\n",
    "    2. Skip rows where Trade Name or Active Ingredient(s) are blank\n",
    "    \"\"\"\n",
    "    \n",
    "    # File paths\n",
    "    # Change the file name\n",
    "    excel_file = \"dataset/drugdata/DICT_rank.xlsx\" \n",
    "    output_file = \"dataset/drugdata/DICT_rank.csv\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"DICTrank Dataset - Excel to CSV Converter\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Check if Excel file exists\n",
    "    if not Path(excel_file).exists():\n",
    "        print(f\"\\n‚ùå Error: File '{excel_file}' not found!\")\n",
    "        print(\"\\nPlease ensure the Excel file is in the same directory as this script.\")\n",
    "        print(\"Or update the 'excel_file' variable in the script with correct path.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Load Excel file\n",
    "        print(f\"\\nüìÇ Loading Excel file: {excel_file}\")\n",
    "        df = pd.read_excel(excel_file, engine='openpyxl')\n",
    "        print(f\"‚úì Loaded {len(df)} rows and {len(df.columns)} columns\")\n",
    "        \n",
    "        # Display column names\n",
    "        print(f\"\\nüìã Columns found: {list(df.columns)}\")\n",
    "        \n",
    "        initial_rows = len(df)\n",
    "        \n",
    "        # Step 1: Remove rows where Trade Name OR Active Ingredient(s) are blank\n",
    "        print(\"\\nüîç Checking for blank Trade Name or Active Ingredient(s)...\")\n",
    "        \n",
    "        # Check for blank/null values in Trade Name and Active Ingredient(s)\n",
    "        mask_trade_name = df['Trade Name'].isna() | (df['Trade Name'].astype(str).str.strip() == '')\n",
    "        mask_active_ingredient = df['Active Ingredient(s)'].isna() | (df['Active Ingredient(s)'].astype(str).str.strip() == '')\n",
    "        \n",
    "        # Combine masks - remove if either is blank\n",
    "        rows_to_remove = mask_trade_name | mask_active_ingredient\n",
    "        blank_rows_count = rows_to_remove.sum()\n",
    "        \n",
    "        if blank_rows_count > 0:\n",
    "            print(f\"‚ö†Ô∏è  Found {blank_rows_count} rows with blank Trade Name or Active Ingredient(s)\")\n",
    "            print(f\"   These rows will be skipped.\")\n",
    "            df = df[~rows_to_remove].copy()\n",
    "            print(f\"‚úì Removed {blank_rows_count} rows\")\n",
    "        else:\n",
    "            print(\"‚úì No blank Trade Name or Active Ingredient(s) found\")\n",
    "        \n",
    "        # Step 2: Fill NA in Keywords (Column G)\n",
    "        print(\"\\nüìù Processing Keywords column...\")\n",
    "        if 'Keywords' in df.columns:\n",
    "            missing_keywords = df['Keywords'].isna().sum()\n",
    "            empty_keywords = (df['Keywords'].astype(str).str.strip() == '').sum()\n",
    "            total_missing_keywords = missing_keywords + empty_keywords\n",
    "            \n",
    "            if total_missing_keywords > 0:\n",
    "                print(f\"   Found {total_missing_keywords} missing values in Keywords\")\n",
    "                df['Keywords'] = df['Keywords'].fillna('NA')\n",
    "                df.loc[df['Keywords'].astype(str).str.strip() == '', 'Keywords'] = 'NA'\n",
    "                print(f\"‚úì Filled with 'NA'\")\n",
    "            else:\n",
    "                print(\"‚úì No missing values in Keywords\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Keywords column not found\")\n",
    "        \n",
    "        # Step 3: Fill NA in DIC Severity Level (Column H)\n",
    "        print(\"\\nüìù Processing DIC Severity Level column...\")\n",
    "        if 'DIC Severity Level' in df.columns:\n",
    "            missing_severity = df['DIC Severity Level'].isna().sum()\n",
    "            empty_severity = (df['DIC Severity Level'].astype(str).str.strip() == '').sum()\n",
    "            total_missing_severity = missing_severity + empty_severity\n",
    "            \n",
    "            if total_missing_severity > 0:\n",
    "                print(f\"   Found {total_missing_severity} missing values in DIC Severity Level\")\n",
    "                df['DIC Severity Level'] = df['DIC Severity Level'].fillna('NA')\n",
    "                df.loc[df['DIC Severity Level'].astype(str).str.strip() == '', 'DIC Severity Level'] = 'NA'\n",
    "                print(f\"‚úì Filled with 'NA'\")\n",
    "            else:\n",
    "                print(\"‚úì No missing values in DIC Severity Level\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  DIC Severity Level column not found\")\n",
    "        \n",
    "        # Save to CSV\n",
    "        print(f\"\\nüíæ Saving to CSV: {output_file}\")\n",
    "        df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "        \n",
    "        final_rows = len(df)\n",
    "        \n",
    "        # Summary\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"‚úÖ CONVERSION COMPLETE!\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"üìä Summary:\")\n",
    "        print(f\"   - Initial rows: {initial_rows}\")\n",
    "        print(f\"   - Rows skipped (blank Trade Name/Active Ingredient): {blank_rows_count}\")\n",
    "        print(f\"   - Final rows in CSV: {final_rows}\")\n",
    "        print(f\"   - Output file: {output_file}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Display sample\n",
    "        print(\"\\nüìÑ Sample of converted data (first 5 rows):\")\n",
    "        print(df.head().to_string())\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n‚ùå Error: Could not find the file '{excel_file}'\")\n",
    "        print(\"Please check the file name and path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error occurred: {str(e)}\")\n",
    "        print(\"\\nPlease check:\")\n",
    "        print(\"1. The Excel file format is correct (.xlsx)\")\n",
    "        print(\"2. The file is not open in another program\")\n",
    "        print(\"3. Required packages are installed: pandas, openpyxl\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313958fa",
   "metadata": {},
   "source": [
    "### 3. Creating chem pub name of drugs code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244dbc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your existing data\n",
    "# be sure the path is correct\n",
    "df = pd.read_csv('dataset/drugdata/drug_smiles.csv') # Make sure this matches your file name\n",
    "\n",
    "# Create lists to store results\n",
    "drug_ids = []\n",
    "drug_names = []\n",
    "\n",
    "print(f\"üîÑ Fetching names for {len(df)} drugs... this may take a few minutes.\")\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    did = row['drug_id']\n",
    "    smiles = row['smiles']\n",
    "    \n",
    "    try:\n",
    "        # Strategy 1: Try to search by SMILES (most accurate)\n",
    "        compounds = pcp.get_compounds(smiles, namespace='smiles')\n",
    "        \n",
    "        if compounds:\n",
    "            # Get the first synonym (usually the common name)\n",
    "            # We limit synonyms to find a short one\n",
    "            found_name = compounds[0].synonyms[0] if compounds[0].synonyms else compounds[0].iupac_name\n",
    "        else:\n",
    "            found_name = did # Fallback to ID if not found\n",
    "            \n",
    "    except Exception as e:\n",
    "        found_name = did # Fallback on error\n",
    "        \n",
    "    drug_ids.append(did)\n",
    "    drug_names.append(found_name)\n",
    "    \n",
    "    # Sleep briefly to be polite to the API\n",
    "    time.sleep(0.2)\n",
    "\n",
    "# Save the new mapping file\n",
    "name_df = pd.DataFrame({'drug_id': drug_ids, 'drug_name': drug_names})\n",
    "name_df.to_csv('drug_names.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Success! 'drug_names.csv' created.\")\n",
    "print(name_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
