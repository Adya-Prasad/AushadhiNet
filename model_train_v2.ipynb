{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Attention Networks (GAT) - Complete Professional Implementation\n",
    "\n",
    "This notebook provides a comprehensive implementation of Graph Attention Networks (GAT) based on the paper \"Graph Attention Networks\" by Veliƒçkoviƒá et al.\n",
    "\n",
    "### Key Features:\n",
    "- ‚úÖ Multi-head attention mechanism\n",
    "- ‚úÖ Professional training pipeline with early stopping\n",
    "- ‚úÖ Comprehensive evaluation metrics\n",
    "- ‚úÖ Visualization capabilities\n",
    "- ‚úÖ Error handling and logging\n",
    "\n",
    "### Architecture Overview:\n",
    "GATs work on graph training_data where nodes represent entities and edges represent relationships. The attention mechanism allows nodes to focus on the most relevant neighbors, similar to transformers but adapted for graph structures.\n",
    "\n",
    "```bash\n",
    "# Custom implementation - EDGE CLASSIFICATION\n",
    "class GraphAttentionLayer:\n",
    "    - Manual attention computation\n",
    "    - Sparse edge-based processing\n",
    "    - Memory-efficient scatter operations\n",
    "    - Gradient checkpointing\n",
    "    \n",
    "class GAT_DDI:\n",
    "    - 3 GAT layers (256 ‚Üí 256 ‚Üí 128 hidden dims)\n",
    "    - Edge MLP: 256 ‚Üí 128 ‚Üí 64 ‚Üí 86 classes\n",
    "    - Processes: node_features ‚Üí embeddings ‚Üí edge_features ‚Üí 86-way classification\n",
    "```\n",
    "```bash\n",
    "# For EACH batch of 7000 edges:\n",
    "1. Forward pass through 3 custom GAT layers\n",
    "2. Extract source/dest node embeddings\n",
    "3. Concatenate edge features\n",
    "4. Pass through 4-layer MLP\n",
    "5. Compute CrossEntropyLoss over 86 classes\n",
    "6. Backward pass with gradient checkpointing\n",
    "7. Repeat for ~27 batches per epoch\n",
    "\n",
    "# Per epoch: ~27 batches √ó complex operations = SLOW\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "from safetensors.torch import save_file, load_file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator, Descriptors\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce GTX 1650\n",
      "GPU Memory: 4.00 GB\n",
      "Memory optimization enabled ‚úì\n",
      "‚úì Directory `images/` exists\n",
      "‚úì Directory `models/` exists\n",
      "‚úì Directory `results/` exists\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "# Memory optimization settings for GPU, Aggressive memory management\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "    \n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(\"Memory optimization enabled ‚úì\")\n",
    "\n",
    "# specific style date time saving\n",
    "timestamp = datetime.now().strftime(\"%d_%b_%H-%M\")\n",
    "\n",
    "# validating required directories:\n",
    "required_directories = ['images', 'models', 'results']\n",
    "for folder in required_directories:\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"‚úò Directory `{folder}/` not found \\nCreating...\")\n",
    "        os.makedirs(folder)\n",
    "    else:\n",
    "        print(f\"‚úì Directory `{folder}/` exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training_data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPLORING DRUG-DRUG INTERACTION DATASET\n",
      "\n",
      "üìä DDI Dataset Shape: (191808, 4)\n",
      "Columns: ['d1', 'd2', 'type', 'Neg samples']\n",
      "\n",
      "üî¨ Interaction Types Distribution:\n",
      "type\n",
      "48    60751\n",
      "46    34360\n",
      "72    23779\n",
      "74     9470\n",
      "59     8397\n",
      "      ...  \n",
      "42       11\n",
      "61       11\n",
      "51       10\n",
      "25        7\n",
      "41        6\n",
      "Name: count, Length: 86, dtype: int64\n",
      "\n",
      "üìã Sample DDI training_data:\n",
      "        d1       d2  type Neg samples\n",
      "0  DB04571  DB00460     0   DB01579$t\n",
      "1  DB00855  DB00460     0   DB01178$t\n",
      "2  DB09536  DB00460     0   DB06626$t\n",
      "3  DB01600  DB00460     0   DB01588$t\n",
      "4  DB09000  DB00460     0   DB06196$t\n",
      "5  DB11630  DB00460     0   DB00744$t\n",
      "6  DB00553  DB00460     0   DB06413$t\n",
      "7  DB06261  DB00460     0   DB00876$t\n",
      "8  DB01878  DB00460     0   DB09267$t\n",
      "9  DB00140  DB00460     0   DB01204$t\n",
      "\n",
      "üíä Drug SMILES Dataset Shape: (1706, 2)\n",
      "Columns: ['drug_id', 'smiles']\n",
      "\n",
      "üìã Sample SMILES training_data:\n",
      "   drug_id                                             smiles\n",
      "0  DB04571                CC1=CC2=CC3=C(OC(=O)C=C3C)C(C)=C2O1\n",
      "1  DB00855                                    NCC(=O)CCC(O)=O\n",
      "2  DB09536                                           O=[Ti]=O\n",
      "3  DB01600              CC(C(O)=O)C1=CC=C(S1)C(=O)C1=CC=CC=C1\n",
      "4  DB09000         CC(CN(C)C)CN1C2=CC=CC=C2SC2=C1C=C(C=C2)C#N\n",
      "5  DB11630  Oc1cccc(-c2c3nc(c(-c4cccc(O)c4)c4ccc([nH]4)c(-...\n",
      "6  DB00553                     COC1=C2OC(=O)C=CC2=CC2=C1OC=C2\n",
      "7  DB06261                      [H]N([H])CC(=O)CCC(=O)OCCCCCC\n",
      "8  DB01878                        O=C(C1=CC=CC=C1)C1=CC=CC=C1\n",
      "9  DB00140  CC1=C(C)C=C2N(C[C@H](O)[C@H](O)[C@H](O)CO)C3=N...\n",
      "\n",
      "üìà Statistics:\n",
      "‚Ä¢ Total DDI pairs: 191808\n",
      "‚Ä¢ Unique drugs in DDI: 1706\n",
      "‚Ä¢ Drugs with SMILES: 1706\n",
      "‚Ä¢ Interaction type 0: 11\n",
      "‚Ä¢ Interaction type 1: 323\n",
      "‚Ä¢ Drugs with both DDI and SMILES: 1706\n",
      "‚Ä¢ Coverage: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Load DDI training_data\n",
    "print(\"EXPLORING DRUG-DRUG INTERACTION DATASET\")\n",
    "\n",
    "# Load DDI interactions\n",
    "ddi_df = pd.read_csv('dataset/drugdata/ddis.csv')\n",
    "print(f\"\\nüìä DDI Dataset Shape: {ddi_df.shape}\")\n",
    "print(f\"Columns: {ddi_df.columns.tolist()}\")\n",
    "print(f\"\\nüî¨ Interaction Types Distribution:\")\n",
    "print(ddi_df['type'].value_counts())\n",
    "print(f\"\\nüìã Sample DDI training_data:\")\n",
    "print(ddi_df.head(10))\n",
    "\n",
    "# Load drug SMILES\n",
    "smiles_df = pd.read_csv('dataset/drugdata/drug_smiles.csv')\n",
    "print(f\"\\nüíä Drug SMILES Dataset Shape: {smiles_df.shape}\")\n",
    "print(f\"Columns: {smiles_df.columns.tolist()}\")\n",
    "print(f\"\\nüìã Sample SMILES training_data:\")\n",
    "print(smiles_df.head(10))\n",
    "\n",
    "# Get unique drugs\n",
    "unique_drugs_ddi = set(ddi_df['d1'].unique()) | set(ddi_df['d2'].unique())\n",
    "print(f\"\\nüìà Statistics:\")\n",
    "print(f\"‚Ä¢ Total DDI pairs: {len(ddi_df)}\")\n",
    "print(f\"‚Ä¢ Unique drugs in DDI: {len(unique_drugs_ddi)}\")\n",
    "print(f\"‚Ä¢ Drugs with SMILES: {len(smiles_df)}\")\n",
    "print(f\"‚Ä¢ Interaction type 0: {(ddi_df['type'] == 0).sum()}\")\n",
    "print(f\"‚Ä¢ Interaction type 1: {(ddi_df['type'] == 1).sum()}\")\n",
    "\n",
    "# Check overlap\n",
    "drugs_with_smiles = set(smiles_df['drug_id'].unique())\n",
    "overlap = unique_drugs_ddi & drugs_with_smiles\n",
    "print(f\"‚Ä¢ Drugs with both DDI and SMILES: {len(overlap)}\")\n",
    "print(f\"‚Ä¢ Coverage: {len(overlap)/len(unique_drugs_ddi)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sanitation & Integrity Checks\n",
    "\n",
    "A compact, professional data-sanity utility to validate CSV files, check missing/invalid values, SMILES validity (RDKit), duplicates, and DDI/SMILES coverage. Use before running feature extraction and graph building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Sanity utilities\n",
    "\n",
    "\n",
    "def sanity_check_dataset(ddi_path='dataset/drugdata/ddis.csv',\n",
    "                         smiles_path='dataset/drugdata/drug_smiles.csv',\n",
    "                         save_report=True):\n",
    "    \"\"\"Run quick, informative checks on DDI and SMILES csv files.\n",
    "\n",
    "    Returns a report dict. Does NOT modify files by default.\n",
    "    \"\"\"\n",
    "    report = {'files': {}}\n",
    "\n",
    "    # --- DDI file checks ---\n",
    "    try:\n",
    "        ddi_df = pd.read_csv(ddi_path)\n",
    "    except Exception as e:\n",
    "        report['files']['ddi'] = {'error': str(e)}\n",
    "        print(f\"‚úó Failed to read {ddi_path}: {e}\")\n",
    "        return report\n",
    "\n",
    "    # Basic checks\n",
    "    report['files']['ddi'] = {\n",
    "        'path': ddi_path,\n",
    "        'shape': ddi_df.shape,\n",
    "        'columns': ddi_df.columns.tolist(),\n",
    "        'missing_per_column': ddi_df.isnull().sum().to_dict(),\n",
    "        'duplicate_pairs': int(ddi_df.duplicated(subset=['d1','d2']).sum()) if set(['d1','d2']).issubset(ddi_df.columns) else None\n",
    "    }\n",
    "\n",
    "    # Validate required columns\n",
    "    req = ['d1', 'd2', 'type']\n",
    "    for c in req:\n",
    "        if c not in ddi_df.columns:\n",
    "            print(f\"‚úó Column `{c}` missing in {ddi_path}\")\n",
    "\n",
    "    # Interaction type checks\n",
    "    if 'type' in ddi_df.columns:\n",
    "        report['files']['ddi']['type_unique_values'] = ddi_df['type'].unique().tolist()\n",
    "        # Check numeric / unexpected strings\n",
    "        report['files']['ddi']['type_non_numeric'] = int(~ddi_df['type'].apply(lambda x: isinstance(x, (int, float))).fillna(False).sum())\n",
    "\n",
    "    # --- SMILES file checks ---\n",
    "    try:\n",
    "        smiles_df = pd.read_csv(smiles_path)\n",
    "    except Exception as e:\n",
    "        report['files']['smiles'] = {'error': str(e)}\n",
    "        print(f\"‚úó Failed to read {smiles_path}: {e}\")\n",
    "        return report\n",
    "\n",
    "    report['files']['smiles'] = {\n",
    "        'path': smiles_path,\n",
    "        'shape': smiles_df.shape,\n",
    "        'columns': smiles_df.columns.tolist(),\n",
    "        'missing_per_column': smiles_df.isnull().sum().to_dict()\n",
    "    }\n",
    "\n",
    "    if not set(['drug_id','smiles']).issubset(smiles_df.columns):\n",
    "        print('‚úó Expect `drug_id` and `smiles` columns in SMILES file')\n",
    "    else:\n",
    "        # validate SMILES\n",
    "        valid_mask = []\n",
    "        invalid_examples = []\n",
    "        for idx, sm in enumerate(smiles_df['smiles'].fillna('')):\n",
    "            mol = Chem.MolFromSmiles(sm)\n",
    "            if mol is None:\n",
    "                valid_mask.append(False)\n",
    "                if len(invalid_examples) < 10:\n",
    "                    invalid_examples.append((int(smiles_df.loc[idx,'drug_id']) if 'drug_id' in smiles_df.columns else idx, sm))\n",
    "            else:\n",
    "                valid_mask.append(True)\n",
    "\n",
    "        n_invalid = int(sum([not v for v in valid_mask]))\n",
    "        report['files']['smiles']['n_invalid_smiles'] = n_invalid\n",
    "        report['files']['smiles']['invalid_examples'] = invalid_examples\n",
    "\n",
    "    # --- Cross-file checks ---\n",
    "    ddi_drugs = set(ddi_df['d1'].unique()) | set(ddi_df['d2'].unique())\n",
    "    smiles_drugs = set(smiles_df['drug_id'].unique()) if 'drug_id' in smiles_df.columns else set()\n",
    "    missing_smiles_for_ddi = list(ddi_drugs - smiles_drugs)\n",
    "    report['cross'] = {\n",
    "        'num_unique_drugs_ddi': len(ddi_drugs),\n",
    "        'num_drugs_with_smiles': len(smiles_drugs),\n",
    "        'num_missing_smiles_for_ddi': len(missing_smiles_for_ddi),\n",
    "        'sample_missing_drugs': missing_smiles_for_ddi[:20]\n",
    "    }\n",
    "\n",
    "    # Basic distribution info for interaction types\n",
    "    if 'type' in ddi_df.columns:\n",
    "        report['files']['ddi']['type_counts'] = ddi_df['type'].value_counts().to_dict()\n",
    "\n",
    "    # Save report\n",
    "    if save_report:\n",
    "        out_path = f'data_sanity_report_{timestamp}.json'\n",
    "        with open(out_path, 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "        print(f\"‚úì Data sanity report saved to {out_path}\")\n",
    "\n",
    "    print('\\n'.join([\n",
    "        f\"‚Ä¢ DDI: {report['files']['ddi'].get('shape')} | Missing cols: {report['files']['ddi']['missing_per_column']}\",\n",
    "        f\"‚Ä¢ SMILES: {report['files']['smiles'].get('shape')} | Invalid SMILES: {report['files']['smiles'].get('n_invalid_smiles')}\",\n",
    "        f\"‚Ä¢ Missing SMILES for DDI drugs: {report['cross']['num_missing_smiles_for_ddi']}\"\n",
    "    ]))\n",
    "\n",
    "    return report\n",
    "\n",
    "\n",
    "# Quick helper to drop rows with invalid SMILES (only when you want to permanently fix data)\n",
    "def drop_invalid_smiles(smiles_df, inplace=False):\n",
    "    df = smiles_df if inplace else smiles_df.copy()\n",
    "    valid_rows = df['smiles'].apply(lambda s: Chem.MolFromSmiles(str(s)) is not None)\n",
    "    dropped = int((~valid_rows).sum())\n",
    "    df = df[valid_rows].reset_index(drop=True)\n",
    "    print(f\"Removed {dropped} rows with invalid SMILES\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature and Pattern Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugFeatureExtractor:\n",
    "    \"\"\"Extract molecular features from SMILES strings using RDKit\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feature_names = []\n",
    "    \n",
    "    def smiles_to_features(self, smiles):\n",
    "        \"\"\"\n",
    "        Convert SMILES to molecular fingerprint and descriptors\n",
    "        Args: smiles: SMILES string\n",
    "        Returns: Feature vector\n",
    "        \"\"\"\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is None:\n",
    "                return None\n",
    "            # Morgan fingerprint\n",
    "            mfpgen = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=1024)\n",
    "            fp = fp = mfpgen.GetFingerprint(mol)\n",
    "            fp_array = np.array(fp)\n",
    "            \n",
    "            # Molecular descriptors\n",
    "            descriptors = [\n",
    "                Descriptors.MolWt(mol),\n",
    "                Descriptors.MolLogP(mol),\n",
    "                Descriptors.NumHDonors(mol),\n",
    "                Descriptors.NumHAcceptors(mol),\n",
    "                Descriptors.TPSA(mol),\n",
    "                Descriptors.NumRotatableBonds(mol),\n",
    "                Descriptors.NumAromaticRings(mol),\n",
    "                Descriptors.FractionCSP3(mol),\n",
    "            ]\n",
    "            \n",
    "            # Combine fingerprint and descriptors\n",
    "            features = np.concatenate([fp_array, descriptors])\n",
    "            \n",
    "            return features\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing SMILES: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_all_features(self, smiles_df):\n",
    "        \"\"\"\n",
    "        Extract features for all drugs        \n",
    "        Args: smiles_df: DataFrame with drug_id and smiles columns\n",
    "        Returns: Dictionary mapping drug_id to feature vector\n",
    "        \"\"\"\n",
    "        print(\"\\n\"+\"_\"*45)\n",
    "        print(\"Extracting molecular features from SMILES...\")\n",
    "        print(\"-\"*45)\n",
    "\n",
    "        drug_features = {}\n",
    "        failed = 0\n",
    "        \n",
    "        for idx, row in smiles_df.iterrows():\n",
    "            drug_id = row['drug_id']\n",
    "            smiles = row['smiles']\n",
    "            \n",
    "            features = self.smiles_to_features(smiles)\n",
    "            \n",
    "            if features is not None:\n",
    "                drug_features[drug_id] = features\n",
    "            else:\n",
    "                failed += 1\n",
    "            \n",
    "            if (idx + 1) % 200 == 0:\n",
    "                print(f\"{idx + 1}/{len(smiles_df)} drugs processed \")\n",
    "        print(\"-\"*45)\n",
    "        print(f\"‚úì Extracted features for {len(drug_features)} drugs\")\n",
    "        if failed > 0:\n",
    "            print(f\"‚ö† Failed to process {failed} drugs\")\n",
    "        print(\"_\"*45 + \"\\n\")\n",
    "        return drug_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GAT Architecture Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDIGraphBuilder:\n",
    "    \"\"\"Build graph structure from DDI training_data\"\"\"\n",
    "    def __init__(self, ddi_df, drug_features):\n",
    "        self.ddi_df = ddi_df\n",
    "        self.drug_features = drug_features\n",
    "        self.drug_to_idx = {}\n",
    "        self.idx_to_drug = {}\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        \n",
    "    def build_graph(self):\n",
    "        \"\"\"\n",
    "        Build graph from DDI training_data        \n",
    "        Returns: Node features, edge indices, edge labels\n",
    "        \"\"\"\n",
    "        print(\"Building DDI graph...\")\n",
    "        \n",
    "        # Get unique drugs\n",
    "        unique_drugs = sorted(list(self.drug_features.keys()))\n",
    "        self.drug_to_idx = {drug: idx for idx, drug in enumerate(unique_drugs)}\n",
    "        self.idx_to_drug = {idx: drug for drug, idx in self.drug_to_idx.items()}\n",
    "        \n",
    "        print(f\"‚Ä¢ Number of nodes (drugs): {len(unique_drugs)}\")\n",
    "        \n",
    "        # Create node feature matrix\n",
    "        feature_dim = len(list(self.drug_features.values())[0])\n",
    "        node_features = np.zeros((len(unique_drugs), feature_dim))\n",
    "        \n",
    "        for drug, idx in self.drug_to_idx.items():\n",
    "            node_features[idx] = self.drug_features[drug]\n",
    "        \n",
    "        # Normalize features\n",
    "        node_features = (node_features - node_features.mean(axis=0)) / (node_features.std(axis=0) + 1e-8)\n",
    "        \n",
    "        # Build edges from DDI training_data\n",
    "        edge_list = []\n",
    "        edge_labels = []\n",
    "        \n",
    "        for _, row in self.ddi_df.iterrows():\n",
    "            d1, d2, interaction_type = row['d1'], row['d2'], row['type']\n",
    "            \n",
    "            if d1 in self.drug_to_idx and d2 in self.drug_to_idx:\n",
    "                idx1 = self.drug_to_idx[d1]\n",
    "                idx2 = self.drug_to_idx[d2]\n",
    "                \n",
    "                # Add bidirectional edges\n",
    "                edge_list.append([idx1, idx2])\n",
    "                edge_list.append([idx2, idx1])\n",
    "                edge_labels.append(interaction_type)\n",
    "                edge_labels.append(interaction_type)\n",
    "        \n",
    "        edge_index = torch.tensor(edge_list, dtype=torch.long).t()\n",
    "        \n",
    "        # Encode labels\n",
    "        edge_labels = self.label_encoder.fit_transform(edge_labels)\n",
    "        edge_labels = torch.tensor(edge_labels, dtype=torch.long)\n",
    "        \n",
    "        print(f\"‚Ä¢ Number of edges: {len(edge_list)}\")\n",
    "        print(f\"‚Ä¢ Number of interaction types: {len(self.label_encoder.classes_)}\")\n",
    "        print(f\"‚Ä¢ Feature dimension: {feature_dim}\")\n",
    "        \n",
    "        return (\n",
    "            torch.FloatTensor(node_features),\n",
    "            edge_index,\n",
    "            edge_labels,\n",
    "            len(self.label_encoder.classes_)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAttentionLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Attention Layer Implementation \n",
    "    Args:\n",
    "        in_features: Number of input features per node (F)\n",
    "        out_features: Number of output features per node (F')\n",
    "        n_heads: Number of attention heads (K)\n",
    "        is_concat: Whether to concatenate or average multi-head results\n",
    "        dropout: Dropout probability for regularization\n",
    "        leaky_relu_negative_slope: Negative slope for LeakyReLU activation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_features: int, out_features: int, n_heads: int=8, \n",
    "                 is_concat: bool = True, dropout: float = 0.6, \n",
    "                 leaky_relu_negative_slope: float = 0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.is_concat = is_concat\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        # Calculate dimensions per head\n",
    "        if is_concat:\n",
    "            assert out_features % n_heads == 0, \"out_features must be divisible by n_heads when concatenating\"\n",
    "            self.n_hidden = out_features // n_heads\n",
    "        else:\n",
    "            self.n_hidden = out_features\n",
    "        \n",
    "        # Linear transformation: W in the paper\n",
    "        self.linear = nn.Linear(in_features, self.n_hidden * n_heads, bias=False)\n",
    "        \n",
    "        # Attention parameters (a^T) (one per head)\n",
    "        self.attn_src = nn.Parameter(torch.Tensor(1, n_heads, self.n_hidden))\n",
    "        self.attn_dst = nn.Parameter(torch.Tensor(1, n_heads, self.n_hidden))\n",
    "        \n",
    "        # Activation and normalization\n",
    "        self.activation = nn.LeakyReLU(negative_slope=leaky_relu_negative_slope)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Initialize weights using Xavier uniform\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize layer weights using Xavier uniform initialization\"\"\"\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "        nn.init.xavier_uniform_(self.attn_src)\n",
    "        nn.init.xavier_uniform_(self.attn_dst)\n",
    "    \n",
    "    def forward(self, h: torch.Tensor, adj_mat: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the attention layer\n",
    "        Args:\n",
    "            h: Node embeddings [n_nodes, in_features]\n",
    "            adj_mat: Adjacency matrix [n_nodes, n_nodes, n_heads]\n",
    "        Returns: Updated node embeddings [n_nodes, out_features]\n",
    "        \"\"\"\n",
    "        n_nodes = h.shape[0]\n",
    "        device = h.device\n",
    "        \n",
    "        # Step 1: Linear transformation g_i = W * h_i for each head\n",
    "        g = self.linear(h).view(n_nodes, self.n_heads, self.n_hidden)\n",
    "\n",
    "        # Extract edge indices from adjacency matrix (ony non-zero entries)\n",
    "        adj_2d = adj_mat.squeeze(-1)\n",
    "        edge_index = adj_2d.nonzero(as_tuple=False).t()\n",
    "\n",
    "        if edge_index.shape[1] == 0:\n",
    "            # No edges case\n",
    "            if self.is_concat:\n",
    "                return torch.zeros(n_nodes, self.n_heads * self.n_hidden, device=device)\n",
    "            else:\n",
    "                return torch.zeros(n_nodes, self.n_hidden, device=device)\n",
    "        \n",
    "        src_nodes = edge_index[0]\n",
    "        dst_nodes = edge_index[1]\n",
    "        \n",
    "        # Get features for source and destination nodes\n",
    "        g_src = g[src_nodes]  # [n_edges, n_heads, n_hidden]\n",
    "        g_dst = g[dst_nodes]  # [n_edges, n_heads, n_hidden]\n",
    "        \n",
    "        # Compute attention scores (edge-wise, memory efficient)\n",
    "        e_src = (g_src * self.attn_src).sum(dim=-1)  # [n_edges, n_heads]\n",
    "        e_dst = (g_dst * self.attn_dst).sum(dim=-1)  # [n_edges, n_heads]\n",
    "        e = self.activation(e_src + e_dst)  # [n_edges, n_heads]\n",
    "        \n",
    "        # Softmax normalization per destination node\n",
    "        # Group by destination node for proper normalization\n",
    "        alpha = torch.zeros_like(e)\n",
    "        # Process each head separately to save memory\n",
    "        for head in range(self.n_heads):\n",
    "            e_head = e[:, head]\n",
    "            \n",
    "            # Use scatter operations instead of loops\n",
    "            # Create index for scatter\n",
    "            max_dst = dst_nodes.max().item() + 1\n",
    "            \n",
    "            # Compute max for numerical stability\n",
    "            max_vals = torch.full((max_dst,), float('-inf'), device=device)\n",
    "            max_vals.scatter_reduce_(0, dst_nodes, e_head, reduce='amax', include_self=False)\n",
    "            \n",
    "            # Subtract max and exp\n",
    "            e_stable = e_head - max_vals[dst_nodes]\n",
    "            exp_e = torch.exp(e_stable)\n",
    "            \n",
    "            # Sum exp values per destination\n",
    "            sum_exp = torch.zeros(max_dst, device=device)\n",
    "            sum_exp.scatter_add_(0, dst_nodes, exp_e)\n",
    "            \n",
    "            # Normalize\n",
    "            alpha[:, head] = exp_e / (sum_exp[dst_nodes] + 1e-16)\n",
    "        \n",
    "        # Aggregate features using attention weights\n",
    "        out = torch.zeros(n_nodes, self.n_heads, self.n_hidden, device=device)\n",
    "        \n",
    "        # Efficient aggregation using scatter_add\n",
    "        for head in range(self.n_heads):\n",
    "            # Weighted features for this head\n",
    "            weighted_features = g_src[:, head, :] * alpha[:, head].unsqueeze(-1)\n",
    "            \n",
    "            # Aggregate to destination nodes\n",
    "            out[:, head, :].scatter_add_(0, \n",
    "                                         dst_nodes.unsqueeze(-1).expand(-1, self.n_hidden),\n",
    "                                         weighted_features)\n",
    "        \n",
    "        # Concatenate or average heads\n",
    "        if self.is_concat:\n",
    "            return out.reshape(n_nodes, self.n_heads * self.n_hidden)\n",
    "        else:\n",
    "            return out.mean(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT_DDI(nn.Module):\n",
    "    \"\"\"Memory-efficient GAT with Mixed Precision support using PyTorch Geometric's GATv2Conv\"\"\"\n",
    "    \n",
    "    def __init__(self, n_features, n_hidden, n_classes, n_heads=8, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        # Replace custom GAT with optimized GATv2Conv\n",
    "        self.gat1 = GATv2Conv(n_features, n_hidden, heads=n_heads, dropout=dropout, concat=True)\n",
    "        self.gat2 = GATv2Conv(n_hidden * n_heads, n_hidden, heads=n_heads, dropout=dropout, concat=True)\n",
    "        self.gat3 = GATv2Conv(n_hidden * n_heads, n_hidden // 2, heads=n_heads, dropout=dropout, concat=True)\n",
    "        \n",
    "        # Input: concatenated embeddings from src and dst nodes\n",
    "        edge_input_dim = (n_hidden // 2) * n_heads * 2  # *2 because we concatenate src and dst\n",
    "        \n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(edge_input_dim, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(n_hidden, n_hidden // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(n_hidden // 2, n_classes)\n",
    "        )\n",
    "        \n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_index_for_prediction):\n",
    "        \"\"\"\n",
    "        Forward pass using edge_index directly (no adjacency matrix)\n",
    "        Args:\n",
    "            x: Node features [n_nodes, n_features]\n",
    "            edge_index: Graph connectivity [2, n_edges] - for message passing\n",
    "            edge_index_for_prediction: Edges to classify [2, n_prediction_edges]\n",
    "        Returns: Edge predictions [n_prediction_edges, n_classes]\n",
    "        \"\"\"\n",
    "        # FP16 Ensure inputs are float for mixed precision\n",
    "        x = x.float()\n",
    "        # Layer 1\n",
    "        x = self.dropout_layer(x)\n",
    "        x = F.elu(self.gat1(x, edge_index))\n",
    "        # Layer 2\n",
    "        x = self.dropout_layer(x)\n",
    "        x = F.elu(self.gat2(x, edge_index))\n",
    "        # Layer 3\n",
    "        x = self.dropout_layer(x)\n",
    "        x = F.elu(self.gat3(x, edge_index))\n",
    "        # Edge classification\n",
    "        src = edge_index_for_prediction[0]\n",
    "        dst = edge_index_for_prediction[1]\n",
    "        edge_features = torch.cat([x[src], x[dst]], dim=1)\n",
    "        \n",
    "        return self.edge_mlp(edge_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Pipeline\n",
    "\n",
    "Our training pipeline includes:\n",
    "- Early stopping to prevent overfitting\n",
    "- Learning rate scheduling\n",
    "- Comprehensive logging\n",
    "- Model checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ddi_data():\n",
    "    \"\"\"Load and prepare DDI data\"\"\"\n",
    "    print(\"_\"*40)\n",
    "    print(\"LOADING DRUG-DRUG INTERACTION DATA\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    # Load data\n",
    "    ddi_df = pd.read_csv('dataset/drugdata/ddis.csv')\n",
    "    smiles_df = pd.read_csv('dataset/drugdata/drug_smiles.csv')\n",
    "    \n",
    "    print(f\"‚úì Loaded {len(ddi_df)} DDI pairs\")\n",
    "    print(f\"‚úì Loaded {len(smiles_df)} drug SMILES\")\n",
    "    print(\"_\"*40)\n",
    "    \n",
    "    # Extract features\n",
    "    feature_extractor = DrugFeatureExtractor()\n",
    "    drug_features = feature_extractor.extract_all_features(smiles_df)\n",
    "    \n",
    "    # Build graph\n",
    "    graph_builder = DDIGraphBuilder(ddi_df, drug_features)\n",
    "    node_features, edge_index, edge_labels, n_classes = graph_builder.build_graph()\n",
    "    \n",
    "    # Create adjacency matrix\n",
    "    n_nodes = node_features.shape[0]\n",
    "    adj_mat = torch.zeros(n_nodes, n_nodes, 1)\n",
    "    adj_mat[edge_index[0], edge_index[1], 0] = 1\n",
    "    \n",
    "    # Add self-loops\n",
    "    adj_mat[range(n_nodes), range(n_nodes), 0] = 1\n",
    "    \n",
    "    # Split data\n",
    "    n_edges = edge_index.shape[1]\n",
    "    indices = np.arange(n_edges)\n",
    "    \n",
    "    train_idx, temp_idx = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n",
    "    \n",
    "    train_mask = torch.zeros(n_edges, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(n_edges, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(n_edges, dtype=torch.bool)\n",
    "    \n",
    "    train_mask[train_idx] = True\n",
    "    val_mask[val_idx] = True\n",
    "    test_mask[test_idx] = True\n",
    "    \n",
    "    print(f\"\\nüõà Data Split:\")\n",
    "    print(f\"‚Ä¢ Train: {train_mask.sum()} edges ({train_mask.sum()/n_edges*100:.1f}%)\")\n",
    "    print(f\"‚Ä¢ Val: {val_mask.sum()} edges ({val_mask.sum()/n_edges*100:.1f}%)\")\n",
    "    print(f\"‚Ä¢ Test: {test_mask.sum()} edges ({test_mask.sum()/n_edges*100:.1f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'node_features': node_features,\n",
    "        'edge_index': edge_index,\n",
    "        'edge_labels': edge_labels,\n",
    "        'adj_mat': adj_mat,\n",
    "        'train_mask': train_mask,\n",
    "        'val_mask': val_mask,\n",
    "        'test_mask': test_mask,\n",
    "        'n_classes': n_classes,\n",
    "        'label_encoder': graph_builder.label_encoder\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Save state_dict as .safetensors + JSON metadata\n",
    "\n",
    "def save_state_dict_as_safetensors(state_dict, path_base, metadata=None):\n",
    "    \"\"\"Save a state_dict (CPU tensors) as .safetensors and metadata as .json\n",
    "    Args:\n",
    "        state_dict: dict of tensors (preferably on CPU)\n",
    "        path_base: e.g. 'models/best_GAT_DDI_01_Feb_12-00' (no extension)\n",
    "        metadata: dict (optional) to save alongside as .json\n",
    "    \"\"\"\n",
    "    safetensor_path = f\"{path_base}.safetensors\"\n",
    "    json_path = f\"{path_base}.json\"\n",
    "    # Ensure CPU tensors\n",
    "    cpu_state = {k: v.cpu() for k, v in state_dict.items()}\n",
    "\n",
    "    try:\n",
    "        save_file(cpu_state, safetensor_path)\n",
    "        print(f\"‚úì Saved safetensors: {safetensor_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Failed to save safetensors: {e}\")\n",
    "        raise\n",
    "\n",
    "    if metadata is not None:\n",
    "        try:\n",
    "            with open(json_path, 'w') as f:\n",
    "                json.dump(metadata, f, indent=2)\n",
    "            print(f\"‚úì Saved metadata: {json_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Failed to save metadata JSON: {e}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# save_state_dict_as_safetensors(model.state_dict(), f'models/end_GAT_DDI_{timestamp}', metadata={'config':config, 'timestamp':timestamp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Load state_dict from .safetensors or .pth and load into model\n",
    "\n",
    "def load_state_dict_from_file(path_base, device='cpu'):\n",
    "    \"\"\"Load state dict from .safetensors (preferred) or fallback to .pth.\n",
    "\n",
    "    Returns a dict suitable for model.load_state_dict()\n",
    "    \"\"\"\n",
    "    safetensor_path = f\"{path_base}.safetensors\"\n",
    "    pth_path = f\"{path_base}.pth\"\n",
    "\n",
    "    if os.path.exists(safetensor_path):\n",
    "        state = load_file(safetensor_path)\n",
    "        # move to device\n",
    "        state = {k: v.to(device) for k, v in state.items()}\n",
    "        print(f\"‚úì Loaded safetensors from {safetensor_path}\")\n",
    "        return state\n",
    "    elif os.path.exists(pth_path):\n",
    "        state = torch.load(pth_path, map_location=device)\n",
    "        print(f\"‚úì Loaded pth state from {pth_path}\")\n",
    "        return state\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No model file found at {safetensor_path} or {pth_path}\")\n",
    "\n",
    "\n",
    "def load_model_from_file(model, path_base, device='cpu'):\n",
    "    state = load_state_dict_from_file(path_base, device=device)\n",
    "    model.load_state_dict(state)\n",
    "    model.to(device)\n",
    "    print(f\"‚úì Model weights loaded into model and moved to {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    \"\"\"Comprehensive evaluation class for GAT models\"\"\"\n",
    "    \n",
    "    def __init__(self, model: GAT_DDI, device: torch.device):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "    \n",
    "    def test(self, data):\n",
    "        \"\"\"Comprehensive testing with multiple metrics\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_edge_index = data['edge_index'][:, data['test_mask']]\n",
    "            out = self.model(data['node_features'].to(self.device), data['edge_index'].to(self.device), test_edge_index.to(self.device))\n",
    "            \n",
    "            pred = out.max(1)[1]\n",
    "            y_true = data['edge_labels'][data['test_mask']].cpu().numpy()\n",
    "            y_pred = pred.cpu().numpy()\n",
    "            \n",
    "            unique_labels = np.unique(np.concatenate([y_true, y_pred]))\n",
    "            \n",
    "            # Calculate metrics\n",
    "            test_acc = accuracy_score(y_true, y_pred)\n",
    "            f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "            \n",
    "            class_report = classification_report(y_true, y_pred, \n",
    "                                                labels=unique_labels,\n",
    "                                                output_dict=True,\n",
    "                                                zero_division=0)\n",
    "            conf_matrix = confusion_matrix(y_true, y_pred, labels=unique_labels)\n",
    "            \n",
    "            return {\n",
    "                'accuracy': test_acc,\n",
    "                'f1_score': f1, \n",
    "                'classification_report': class_report,\n",
    "                'confusion_matrix': conf_matrix,\n",
    "                'predictions': y_pred,\n",
    "                'true_labels': y_true\n",
    "            }\n",
    "    \n",
    "    def visualize_embeddings(self, data, save_path=f'images/GAT_visualize_embeddings_{timestamp}.png'):\n",
    "        \"\"\"Visualize node embeddings using t-SNE (computes node embeddings from model GAT layers)\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = data['node_features'].to(self.device).float()\n",
    "            edge_index = data['edge_index'].to(self.device)\n",
    "\n",
    "            # Compute embeddings using model's GAT layers\n",
    "            h = self.model.dropout_layer(x)\n",
    "            h = F.elu(self.model.gat1(h, edge_index))\n",
    "            h = self.model.dropout_layer(h)\n",
    "            h = F.elu(self.model.gat2(h, edge_index))\n",
    "            h = self.model.dropout_layer(h)\n",
    "            h = F.elu(self.model.gat3(h, edge_index))\n",
    "\n",
    "            embeddings = h.cpu().numpy()\n",
    "\n",
    "            print(\"Computing t-SNE embeddings...\")\n",
    "            tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "            embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "            # Use node degree for coloring as an informative scalar\n",
    "            ei = data['edge_index'].cpu().numpy()\n",
    "            degrees = np.zeros(embeddings.shape[0])\n",
    "            for u in ei[0]:\n",
    "                degrees[u] += 1\n",
    "\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n",
    "                                c=degrees, cmap='viridis', alpha=0.8, s=50)\n",
    "            cbar = plt.colorbar(scatter)\n",
    "            cbar.set_label('Node degree')\n",
    "            plt.title('GAT Node Embeddings Visualization (t-SNE)', fontsize=16, fontweight='bold')\n",
    "            plt.xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "            plt.ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            print(f\"‚úì Saved embeddings visualization to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, save_path=f'images/DDI_training_history_{timestamp}.png'):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history['train_loss'], label='Train', linewidth=2)\n",
    "    axes[0].plot(history['val_loss'], label='Validation', linewidth=2)\n",
    "    axes[0].set_title('Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1].plot(history['train_acc'], label='Train', linewidth=2)\n",
    "    axes[1].plot(history['val_acc'], label='Validation', linewidth=2)\n",
    "    axes[1].set_title('Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # F1-Score\n",
    "    axes[2].plot(history['train_f1'], label='Train', linewidth=2)\n",
    "    axes[2].plot(history['val_f1'], label='Validation', linewidth=2)\n",
    "    axes[2].set_title('F1-Score', fontsize=14, fontweight='bold')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('F1-Score')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"‚úì Saved training history to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "training_data = prepare_ddi_data()\n",
    "\n",
    "# Remove unused adjacency matrix to save VRAM\n",
    "del training_data['adj_mat']\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Move to device\n",
    "for key in ['node_features', 'edge_index', 'edge_labels', \n",
    "            'train_mask', 'val_mask', 'test_mask']:\n",
    "    training_data[key] =    training_data[key].to(device)\n",
    "\n",
    "# Model configuration\n",
    "config = {\n",
    "    'n_features': training_data['node_features'].shape[1],\n",
    "    'n_hidden': 128, # 256 OR 128\n",
    "    'n_classes': training_data['n_classes'],\n",
    "    'n_heads': 4, # 4 OR 8\n",
    "    'dropout': 0.3\n",
    "}\n",
    "print(f\"\\n‚õØ Model Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"‚Ä¢ {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alias for compatibility with older cells\n",
    "data = training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage examples (Sanity check + Saving)\n",
    "\n",
    "Quick usage examples ‚Äî run the data sanity checks before feature extraction and call the trainer with metadata saving enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sanity checks BEFORE prepare_ddi_data()\n",
    "report = sanity_check_dataset()\n",
    "\n",
    "# If you want to drop invalid smiles permanently:\n",
    "# smiles_df = drop_invalid_smiles(pd.read_csv('dataset/drugdata/drug_smiles.csv'))\n",
    "# smiles_df.to_csv('dataset/drugdata/drug_smiles.cleaned.csv', index=False)\n",
    "\n",
    "# Example: include config metadata when training/saving\n",
    "# trainer.train(..., save_metadata={'config': config, 'notes': 'GATv2 experiment'})\n",
    "\n",
    "print('\\n(To save models as .safetensors automatically during training, pass save_metadata to trainer.train)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model_config \u001b[38;5;241m=\u001b[39m GAT_DDI(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mconfig\u001b[49m)\n\u001b[0;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m DDITrainer(model_config, device)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Training Configuration: Train with smaller batch size\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model_config = GAT_DDI(**config)\n",
    "trainer = DDITrainer(model_config, device)\n",
    "\n",
    "# Training Configuration: Train with smaller batch size\n",
    "history = trainer.train(\n",
    "    training_data['node_features'], \n",
    "    training_data['edge_index'],\n",
    "    training_data['edge_labels'], \n",
    "    training_data['train_mask'], \n",
    "    training_data['val_mask'],\n",
    "    epochs=5, \n",
    "    lr=0.001, \n",
    "    weight_decay=5e-4, \n",
    "    patience=30,\n",
    "    batch_size=256  # 800 OR 512 OR 256\n",
    ")\n",
    "\n",
    "# Plot history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a convenience alias for backward compatibility\n",
    "model = model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and evaluate (prefer .safetensors; fallback to .pth)\n",
    "\n",
    "# Create fresh model instance (or reuse existing model_config)\n",
    "model = GAT_DDI(**config)\n",
    "try:\n",
    "    load_model_from_file(model, os.path.join('models', f'best_GAT_DDI_{timestamp}'), device=device)\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö† Best model file not found. Using in-memory model weights (if trained).\")\n",
    "\n",
    "# Evaluate\n",
    "model.to(device)\n",
    "evaluator = ModelEvaluator(model, device)\n",
    "\n",
    "# Ensure training_data variable is used consistently\n",
    "data = training_data\n",
    "\n",
    "test_results = evaluator.test(data)\n",
    "print(f\"üìã Test Result Accuracy: {test_results['accuracy']:.4f}\")\n",
    "print(\"\\nüñÉ Classification Report:\")\n",
    "print(classification_report(test_results['true_labels'], test_results['predictions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model as .safetensors (example)\n",
    "final_base = os.path.join('models', f'final_GAT_DDI_{timestamp}')\n",
    "try:\n",
    "    state_dict_to_save = model.state_dict() if 'model' in globals() else model_config.state_dict()\n",
    "    save_state_dict_as_safetensors(state_dict_to_save, final_base, metadata={'config': config, 'timestamp': timestamp})\n",
    "    print(f\"‚úì Final model saved to {final_base}.safetensors\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Failed to save final model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Model (load best saved weights if available, otherwise use in-memory model)\n",
    "\n",
    "# Use the trained model instance\n",
    "model = model_config\n",
    "try:\n",
    "    load_model_from_file(model, os.path.join('models', f'best_GAT_DDI_{timestamp}'), device=device)\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö† No saved best model found; using current in-memory model weights\")\n",
    "\n",
    "# Evaluate\n",
    "evaluator = ModelEvaluator(model, device)\n",
    "test_results = evaluator.test(training_data)\n",
    "\n",
    "print(f\"üìã Test Result Accuracy: {test_results['accuracy']:.4f}\")\n",
    "print(\"\\nüñÉ Classification Report:\")\n",
    "print(classification_report(test_results['true_labels'], test_results['predictions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüñÉ Classification Report:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = evaluator.test(training_data)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize node embeddings\n",
    "# Uses model (should be loaded/assigned before calling)\n",
    "evaluator = ModelEvaluator(model, device)\n",
    "evaluator.visualize_embeddings(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_top_classes(test_results, top_n=10, save_path=f'images/GAT_confusion_matrix_{timestamp}.png'):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix for top N most frequent classes only\n",
    "    \"\"\"\n",
    "    y_true = test_results['true_labels']\n",
    "    y_pred = test_results['predictions']\n",
    "    \n",
    "    # Get top N most frequent classes in test set\n",
    "    unique, counts = np.unique(y_true, return_counts=True)\n",
    "    top_classes = unique[np.argsort(counts)[-top_n:]][::-1]  # Top N by frequency\n",
    "    \n",
    "    # Filter predictions to only include top classes\n",
    "    mask = np.isin(y_true, top_classes)\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    \n",
    "    # Create confusion matrix for top classes only\n",
    "    conf_matrix = confusion_matrix(y_true_filtered, y_pred_filtered, labels=top_classes)\n",
    "    \n",
    "    # Create class names\n",
    "    class_names = [f'Type {i}' for i in top_classes]\n",
    "    \n",
    "    # Plot with larger figure\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count'}, linewidths=0.5)\n",
    "    \n",
    "    plt.title(f'Confusion Matrix - Top {top_n} Interaction Types', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Predicted Class', fontsize=12)\n",
    "    plt.ylabel('True Class', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úì Saved confusion matrix for top {top_n} classes to {save_path}\")\n",
    "    print(f\"  Top classes: {top_classes}\")\n",
    "\n",
    "# Plot top 10 most frequent interaction types\n",
    "plot_confusion_matrix_top_classes(test_results, top_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_normalized_confusion_matrix(test_results, top_n=15, save_path=f'images/GAT_confusion_matrix_normalized_{timestamp}.png'):\n",
    "    \"\"\"\n",
    "    Plot normalized confusion matrix (percentages) for top N classes\n",
    "    \"\"\"\n",
    "    y_true = test_results['true_labels']\n",
    "    y_pred = test_results['predictions']\n",
    "    \n",
    "    # Get top N classes\n",
    "    unique, counts = np.unique(y_true, return_counts=True)\n",
    "    top_classes = unique[np.argsort(counts)[-top_n:]][::-1]\n",
    "    \n",
    "    # Filter\n",
    "    mask = np.isin(y_true, top_classes)\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    \n",
    "    # Normalized confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true_filtered, y_pred_filtered, labels=top_classes)\n",
    "    conf_matrix_norm = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    class_names = [f'Type {i}' for i in top_classes]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    sns.heatmap(conf_matrix_norm, annot=True, fmt='.2f', cmap='RdYlGn',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Proportion'}, linewidths=0.5,\n",
    "                vmin=0, vmax=1)\n",
    "    \n",
    "    plt.title(f'Normalized Confusion Matrix - Top {top_n} Types', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Predicted Class', fontsize=12)\n",
    "    plt.ylabel('True Class', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úì Saved normalized confusion matrix to {save_path}\")\n",
    "\n",
    "# Plot normalized matrix\n",
    "plot_normalized_confusion_matrix(test_results, top_n=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_summary(test_results, save_path=f'images/GAT_confusion_summary_{timestamp}.png'):\n",
    "    \"\"\"\n",
    "    Plot summary statistics instead of full confusion matrix\n",
    "    \"\"\"\n",
    "    y_true = test_results['true_labels']\n",
    "    y_pred = test_results['predictions']\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    unique_classes = np.unique(y_true)\n",
    "    class_accuracies = []\n",
    "    class_counts = []\n",
    "    \n",
    "    for cls in unique_classes:\n",
    "        mask = y_true == cls\n",
    "        if mask.sum() > 0:\n",
    "            acc = (y_pred[mask] == cls).sum() / mask.sum()\n",
    "            class_accuracies.append(acc)\n",
    "            class_counts.append(mask.sum())\n",
    "        else:\n",
    "            class_accuracies.append(0)\n",
    "            class_counts.append(0)\n",
    "    \n",
    "    # Sort by frequency\n",
    "    sorted_indices = np.argsort(class_counts)[::-1][:20]  # Top 20\n",
    "    \n",
    "    # Plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    ax1.barh([f'Type {unique_classes[i]}' for i in sorted_indices],\n",
    "             [class_accuracies[i] for i in sorted_indices],\n",
    "             color='steelblue')\n",
    "    ax1.set_xlabel('Accuracy', fontsize=12)\n",
    "    ax1.set_title('Per-Class Accuracy (Top 20)', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Class distribution\n",
    "    ax2.barh([f'Type {unique_classes[i]}' for i in sorted_indices],\n",
    "             [class_counts[i] for i in sorted_indices],\n",
    "             color='coral')\n",
    "    ax2.set_xlabel('Sample Count', fontsize=12)\n",
    "    ax2.set_title('Class Distribution (Top 20)', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úì Saved confusion summary to {save_path}\")\n",
    "\n",
    "# Plot summary\n",
    "plot_confusion_summary(test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model performance\n",
    "def analyze_results(history, test_results, data, model):\n",
    "    \"\"\"\n",
    "    Provide comprehensive analysis of model performance\n",
    "    \"\"\"\n",
    "    print(\"üìà MODEL PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Training metrics\n",
    "    print(f\"\\nTraining Metrics:\")\n",
    "    print(f\"‚Ä¢ Final Training Accuracy: {history['train_acc'][-1]:.4f}\")\n",
    "    print(f\"‚Ä¢ Final Dev / Validation Accuracy: {history['val_acc'][-1]:.4f}\")\n",
    "    print(f\"‚Ä¢ Best Validation Accuracy: {max(history['val_acc']):.4f}\")\n",
    "    print(f\"‚Ä¢ Final Training F1: {history['train_f1'][-1]:.4f}\")\n",
    "    print(f\"‚Ä¢ Final Validation F1: {history['val_f1'][-1]:.4f}\")\n",
    "    print(f\"‚Ä¢ Best Validation F1: {max(history['val_f1']):.4f}\")\n",
    "    print(f\"‚Ä¢ Total Epochs: {len(history['train_loss'])}\")\n",
    "    \n",
    "    # Test metrics\n",
    "    print(f\"\\nTest Metrics:\")\n",
    "    print(f\"‚Ä¢ Test Accuracy: {test_results['accuracy']:.4f}\")\n",
    "    if 'f1_score' in test_results:\n",
    "        print(f\"‚Ä¢ Test F1-Score: {test_results['f1_score']:.4f}\")\n",
    "    \n",
    "    # Per-class performance (only for classes in test set)\n",
    "    print(f\"\\nüìä Per-Class Performance:\")\n",
    "    unique_labels = np.unique(test_results['true_labels'])\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_str = str(label)\n",
    "        if label_str in test_results['classification_report']:\n",
    "            report = test_results['classification_report'][label_str]\n",
    "            precision = report['precision']\n",
    "            recall = report['recall']\n",
    "            f1 = report['f1-score']\n",
    "            print(f\"   ‚Ä¢ Type {label}: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")\n",
    "    \n",
    "    # Model complexity\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"\\nüîß Model Complexity:\")\n",
    "    print(f\"   ‚Ä¢ Total Parameters: {total_params:,}\")\n",
    "    print(f\"   ‚Ä¢ Trainable Parameters: {trainable_params:,}\")\n",
    "    print(f\"   ‚Ä¢ Model Size: ~{total_params * 4 / 1024 / 1024:.2f} MB\")\n",
    "    \n",
    "    # Dataset info\n",
    "    print(f\"\\nüìä Dataset Info:\")\n",
    "    print(f\"   ‚Ä¢ Total Drugs (Nodes): {data['node_features'].shape[0]}\")\n",
    "    print(f\"   ‚Ä¢ Total Interactions (Edges): {data['edge_index'].shape[1]}\")\n",
    "    print(f\"   ‚Ä¢ Feature Dimension: {data['node_features'].shape[1]}\")\n",
    "    print(f\"   ‚Ä¢ Number of Interaction Types: {data['n_classes']}\")\n",
    "    print(f\"   ‚Ä¢ Classes in Test Set: {len(unique_labels)}\")\n",
    "\n",
    "# Run analysis\n",
    "analyze_results(history, test_results, data, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model Logs and Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare the new log entry with rounded values\n",
    "current_log = {\n",
    "    \"date\": timestamp,\n",
    "    \"graph_details\": {\n",
    "        \"num_nodes\": data['node_features'].shape[0],  # ‚úÖ ADD: Number of drugs\n",
    "        \"num_edges\": data['edge_index'].shape[1],  # ‚úÖ FIX: Total edges (not just first row)\n",
    "        \"num_interaction_types\": data['n_classes'],\n",
    "        \"feature_dimension\": data['node_features'].shape[1]\n",
    "    },\n",
    "    \"config\": config,\n",
    "    \"runtime_info\": {\n",
    "        \"device\": str(device),\n",
    "        \"total_parameters\": sum(p.numel() for p in model.parameters()),\n",
    "        \"trainable_parameters\": sum(p.numel() for p in model.parameters() if p.requires_grad),  # ‚úÖ ADD\n",
    "        \"model_size_mb\": round(sum(p.numel() for p in model.parameters()) * 4 / 1024 / 1024, 2),  # ‚úÖ ADD\n",
    "        \"training_edges\": int(data['train_mask'].sum()),\n",
    "        \"validation_edges\": int(data['val_mask'].sum()),\n",
    "        \"test_edges\": int(data['test_mask'].sum())  # ‚úÖ ADD: Test set size\n",
    "    },\n",
    "    \"training_info\": {  # ‚úÖ ADD: Training details\n",
    "        \"epochs_completed\": len(history['train_loss']),\n",
    "        \"best_epoch\": history['val_f1'].index(max(history['val_f1'])) + 1,\n",
    "        \"learning_rate\": 0.001,  # From your training config\n",
    "        \"batch_size\": 7000,\n",
    "        \"weight_decay\": 5e-4\n",
    "    },\n",
    "    \"metrics\": {\n",
    "        # Training metrics (rounded to 3 decimals)\n",
    "        \"train_loss\": round(history['train_loss'][-1], 3),  # ‚úÖ ROUNDED\n",
    "        \"train_acc\": round(history['train_acc'][-1], 3),    # ‚úÖ ROUNDED\n",
    "        \"train_f1\": round(history['train_f1'][-1], 3),      # ‚úÖ ROUNDED\n",
    "        \n",
    "        # Validation metrics (rounded to 3 decimals)\n",
    "        \"val_loss\": round(history['val_loss'][-1], 3),      # ‚úÖ ROUNDED\n",
    "        \"val_acc\": round(history['val_acc'][-1], 3),        # ‚úÖ ROUNDED\n",
    "        \"val_f1\": round(history['val_f1'][-1], 3),          # ‚úÖ ROUNDED\n",
    "        \n",
    "        # Best validation metrics\n",
    "        \"best_val_acc\": round(max(history['val_acc']), 3),  # ‚úÖ ADD\n",
    "        \"best_val_f1\": round(max(history['val_f1']), 3),    # ‚úÖ ADD\n",
    "        \n",
    "        # Test metrics (if available)\n",
    "        \"test_acc\": round(test_results['accuracy'], 3) if 'test_results' in locals() else None,  # ‚úÖ ADD\n",
    "        \"test_f1\": round(test_results['f1_score'], 3) if 'test_results' in locals() and 'f1_score' in test_results else None  # ‚úÖ ADD\n",
    "    }\n",
    "}\n",
    "\n",
    "# 2. File handling: Load existing data or create a new list\n",
    "log_file = 'model_evals_log.json'\n",
    "\n",
    "if os.path.exists(log_file):\n",
    "    with open(log_file, 'r') as f:\n",
    "        try:\n",
    "            logs_list = json.load(f)\n",
    "            if not isinstance(logs_list, list):\n",
    "                logs_list = []\n",
    "        except json.JSONDecodeError:\n",
    "            logs_list = []\n",
    "else:\n",
    "    logs_list = []\n",
    "\n",
    "# 3. Insert new log at the TOP (index 0)\n",
    "logs_list.insert(0, current_log)\n",
    "\n",
    "# 4. Save back to file with nice formatting\n",
    "with open(log_file, 'w') as f:\n",
    "    json.dump(logs_list, f, indent=4)\n",
    "\n",
    "print(f\"(‚úì) Log successfully saved to {log_file}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
